---
title: Fairness of AI in Medical Imaging
description: "MICCAI 2024 Workshop"
layout: default
permalink: /2024-miccai/index.html
weight: -1
redirect_from: /2024-miccai/
---

## TL;DR
 - Fairness & Medical Imaging workshop on **Oct 10th** at [MICCAI 2024](https://conferences.miccai.org/2024/en/) (Morocco)
 - Organized jointly with the workshop on [Ethical and Philosophical Issues in Medical Imaging](https://sites.google.com/view/epimi)
 - [Recordings of talks](https://www.youtube.com/watch?v=8EoupgJYP94&list=PL043hPrfrJaPc0E5v-ogus9-fFhu0xUja) are available


## FAIMI Keynote - Dr. Mercy Asiedu
#### Machine Learning Fairness for Health in Africa
<p style="text-align: justify">Applications of artificial intelligence (AI) in healthcare have accelerated exponentially. While AI has the potential to improve healthcare for the better, like other advancements in medical technology, it also has the potential to increase health disparities. Historically, medical technology has not been created with the needs of underserved settings in mind and this has led to limited access in low/middle income countries. Reduced access to these healthcare tools leads to downstream gaps in data used to train machine learning models, and by extension, the potential for machine learning biases, should these models be used on individuals from historically excluded settings. 
In this talk I will discuss the Nteasee Study to understand the general population and expert perspectives on AI for health in Africa, including a deep dive on algorithmic fairness and colonialism. I will then provide a brief overview of my research on developing tools to attempt to overcome some of these limitations, ranging from  African-focussed datasets for LLM evaluation and tuning and applied AI for health equity outcomes. Overall, I hope to make a case for considering geo-contextual perspectives for AI development and evaluation and to demonstrate examples of beneficial AI development for health in Africa.</p>

<div class="clearfix">
	<img class="img2" src="/assets/speakers/Asiedu.jpg" alt="Dr. Mercy Asiedu" width="150" style="float: left; padding:0px 10px 10px 10px">
	<p style="text-align: justify">
		<b>Dr. Mercy Asiedu</b> is a research scientist in the Society Centered AI team at Google Research where she works on fairness in machine learning and generative AI tools for impact driven research for global health. Before that, she was a Schmidt Science Postdoctoral Research Fellow at MIT working on interdisciplinary research projects using generative AI methods to  improve mobile ultrasound imaging. She also worked on projects researching the use of language models to improve comprehension of health notes for breast oncology patients. 
She received her PhD in Biomedical Engineering and a certificate in Global health from Duke University. Her dissertation focused on the research and development of a low-cost imaging device and machine learning algorithms to reduce barriers to cervical cancer screening. She has won several awards for her work including the Inaugural Patrick J. McGovern Tech for Humanity Changemaker Awards, the Lemelson-MIT Graduate Student Inventor Award, and Velji Emerging Leader in Global Health award. 
She has her bachelor’s degree in Biomedical Engineering from the University of Rochester, and high school degree from Holy Child Secondary School, Cape Coast, Ghana.
	</p>
</div>

## EPIMI Keynote - Dr. Xiaoxiao Li 
<div class="clearfix">
	<img class="img2" src="/assets/speakers/Xiaoxiao.jpg" alt="Dr. Xiaoxiao Li" width="150" style="float: left; padding:0px 10px 10px 10px">
	<p style="text-align: justify">
		<b>Dr. Xiaoxiao Li</b> is an Assistant Professor in the Electrical and Computer Engineering Department at the University of British Columbia (UBC), leading the Trusted and Efficient AI (TEA) Group, and an Adjunct Assistant Professor at the School of Medicine at Yale University. Dr. Li specializes in the interdisciplinary field of deep learning and healthcare. Their primary mission is to make AI more reliable, especially when it comes to sensitive areas like healthcare. At the TEA Group, they explore wide-range of topics from fundamental machine learning to more focused healthcare-driven AI solutions. The group delves into topics like learning from multimodal and heterogeneous data, efficient AI models, federated learning, vision-language models, and creating AI models that not only perform tasks but can also be trustworthy. Some of their groundbreaking work includes AI-driven analysis of neuroimages, pathology slides, molecular and clinical notes. In essence, Dr. Li’s work is all about bridging the world of advanced machine learning with the practical needs of the healthcare industry.
	</p>
</div>

## Schedule for FAIMI/EPIMI Workshop

| Time | Speaker and Title |
 |------|-------- |
 |**EPIMI** ||
 | 1:30 - 1:35 | Welcome | 
 | 1:35 - 1:55 | Debesh Jha, et al.: Practical and Ethical Considerations for Generative AI in Medical Imaging | 
 | 1:55 - 2:15 | Emma A.M. Stanley, et al.: Assessing the Impact of Sociotechnical Harms in AI-based Medical Image Analysis
 | 2:15 - 3:00 | **Keynote speaker:** Dr. Xiaoxiao Li - Evaluating Fairness and Mitigating Bias in the Era of Medical Imaging Foundation Models |
 |**FAIMI** ||
 | 3:00 - 3:30 | Welcome + Poster pitch | 
 | 3:30 - 4:00 | Posters/Coffee| 
 | 4:00 - 5:00 | **Keynote speaker:** Dr. Mercy Asiedu - Machine Learning Fairness for health in Africa | 
 | 5:00 - 5:10 | Vincent Olesen, et al.: Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods | 
 | 5:10 - 5:20 | Vien N Dang, et al.: Mitigating Overdiagnosis Bias in CNN-Based Alzheimer's Disease Diagnosis for the Elderly | 
 | 5:20 - 5:30 | Kate E Cevora, et al.: Quantifying the Impact of Population Shift Across Age and Sex for Abdominal Organ Segmentation | 
 | 5:30 - 5:40 | Yuyang Xue, et al.: BMFT: Achieving Fairness via Bias-based Weight Masking Fine-tuning | 
 | 5:40 - 5:50 | Giacomo Nebbia, et al.: Cycle-GANs generated difference maps to interpret race prediction from medical images | 
 | 5:50 - 6:00 | Prizes and closing for FAIMI | 
 
## Accepted Papers

Anissa Alloula, et al.: *On Biases in a UK Biobank-based Retinal Image Classification Model* [Link](https://arxiv.org/abs/2408.02676)

Ulas Bagci, et al.: *Practical and Ethical Considerations for Generative AI in Medical Imaging*

Samia Belhadj, et al.: *Positive-Sum Fairness: Leveraging Demographic Attributes to Achieve Fair AI Outcomes Without Sacrificing Group Gains*

Christopher T Boland, et al.: *All you need is a guiding hand: mitigating shortcut bias in deep learning models for medical imaging*

Ricardo C Brioso, et al.: *Investigating Gender Bias in Lymph-node Segmentation with Anatomical Priors*

Kate E Cevora, et al.: *Quantifying the Impact of Population Shift Across Age and Sex for Abdominal Organ Segmentation*

Vien N Dang, et al.: *Mitigating Overdiagnosis Bias in CNN-Based Alzheimer's Disease Diagnosis for the Elderly*

John J P McCabe, et al.: *Exploring Fairness in State-of-the-Art Pulmonary Nodule Detection Algorithms*

Giacomo Nebbia, et al.: *Cycle-GANs generated difference maps to interpret race prediction from medical images*

Dilermando Queiroz Neto, et al.: *Using Backbone Foundation Model for Evaluation Fairness Without Demographic Data in Chest Radiography*

Vincent Olesen, et al.: *Slicing Through Bias: Explaining Performance Gaps in Medical Image Analysis using Slice Discovery Methods* [Link](https://arxiv.org/abs/2406.12142)

Ralf Raumanns, et al.: *Dataset Distribution Impacts Model Fairness: Single vs. Multi-Task Learning* [Link](https://arxiv.org/abs/2407.17543)

Raissa Souza, et al.: *Do sites benefit equally from distributed learning in medical image analysis?*

Ronald Summers, et al.: *AI Fairness in Medical Imaging: Controlling for Disease Severity*

Yuyang Xue, et al.: *BMFT: Achieving Fairness via Bias-based Weight Masking Fine-tuning*

Alexander Ziller, et al.: *Fair and Private CT Contrast Agent Detection*

## Proceedings

<a href="https://link.springer.com/book/9783031727863">
<img class="img2" src="/images/proceedings2024.png" alt="FAIMI 2024 Proceedings" style="float: center; padding:0px 10px 10px 10px">
</a>
You can access the Proceedings of our FAIMI 2024 workshop at MICCAI [here](https://link.springer.com/book/9783031727863)


## Awards MICCAI FAIMI 2024
Congratulations to <b>Kate E Cevora</b> from  Imperial College London for the best oral presenter award. Congratulations to <b>Raissa Souza</b> from the University of Calgary for the best poster presenter award.


<div class="clearfix">
	<img class="img2" src="/images/FAIMI_2024-Best-oral.png" alt="MICCAI FAIMI 2024 Best Oral" width="300" style="float: left; padding:0px 10px 10px 10px">
	<img class="img2" src="/images/FAIMI_2024-Best-Poster.png" alt="MICCAI FAIMI 2024 Best Poster" width="300" style="float: left; padding:0px 10px 10px 10px">

</div>


## Call for Papers
We invite the submission of papers for

<p style="text-align: center;"><b>FAIMI: The MICCAI 2024 Workshop on Fairness of AI in Medical Imaging</b>.</p>

<p style="text-align: justify">Over the past several years, research on fairness, equity, and accountability in the context of machine learning has extensively demonstrated ethical risks in the deployment of machine learning systems in critical infrastructure, such as medical imaging.
The FAIMI workshop aims to encourage and emphasize research on and discussion of fairness of AI within the medical imaging domain.
We therefore invite the submission of papers, which will be selected for oral or poster presentation at the workshop. 
Topics include but are not limited to:</p>
- Assessment of bias in ML applications for medical imaging  
- Healthcare inequalities and/or the role of ML in addressing these  
- Discussion of definitions of fairness in medical contexts  
- Discussion of applicability of fairness in medical contexts  
- Bias mitigation strategies for ML/medical imaging  
- Ethics of fairness for medical imaging and medicine  
- Legal/regulatory considerations of fairness  
- Causality and fairness in medical imaging  
- The interplay of algorithmic and dataset bias 

<p style="text-align: justify">The workshop proceedings will be published in the MICCAI workshops volumes of the Springer Lecture Notes Computer Science (LNCS) series. 
Papers should be <i>anonymized</i> and at most 8 pages plus at most 2 extra pages of references using the <a href="https://www.springer.com/gp/computer-science/lncs/conference-proceedings-guidelines">LNCS format</a>. 
The review process is conducted in a double-blind manner, following MICCAI standards. 
Submissions are made in <a href="https://cmt3.research.microsoft.com/FAIMI2024">CMT</a>. 
</p>

<p style="text-align: justify">
Following the <a href="https://conferences.miccai.org/2024/en/PAPER-SUBMISSION-AND-REBUTTAL-GUIDELINES.html">MICCAI paper submission guidelines</a>, the submission of additional <b>supplementary material</b> is possible.
This should be a separate file, and reviewers are under no obligation to review it; the paper must be self-contained and understandable without the supplementary material.
Note that in the submission system, supplementary materials can only be added once a regular submission has been created. (You can still edit your submission until the deadline.)
</p>


## Dates

*All dates are [Anywhere on Earth](https://en.wikipedia.org/wiki/Anywhere_on_Earth).*

Abstract / placeholder: **June 24, 2024**

Full Paper Deadline: **~~June 24, 2024~~ June 28, 2024**

Notification of Acceptance: **July 15, 2024**

Camera-ready Version: **August 1, 2024**

Workshop: **October 10th, 2024**


## Organizers

**Aasa Feragen**, DTU Compute, Technical University of Denmark  
**Andrew King**, King's College London  
**Ben Glocker**, Imperial College London  
**Enzo Ferrante**, CONICET, Universidad Nacional del Litoral  
**Eike Petersen**, DTU Compute, Technical University of Denmark  
**Esther Puyol-Antón**, HeartFlow and King's College London  
**Melanie Ganz-Benjaminsen**, University of Copenhagen & Neurobiology Research Unit, Rigshospitalet  
**Veronika Cheplygina**, IT University Copenhagen  

## Contact

Please direct any inquiries related to the workshop or this website to <a href="mailto:faimi-organizers@googlegroups.com">faimi-organizers@googlegroups.com</a>.
